<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
      <title>automated-tests on Roy Tang</title>
      <link>https://mirror.roytang.net/tags/automated-tests/</link>
      <description>Recent content in automated-tests on Roy Tang</description>
      <generator>Hugo -- gohugo.io</generator>
      <language>en-us</language>
      <managingEditor>hello@roytang.net (Roy Tang)</managingEditor>
      <webMaster>hello@roytang.net (Roy Tang)</webMaster>
      <lastBuildDate>Wed, 23 Dec 2009 08:20:52 +0000</lastBuildDate>
      
          <atom:link href="https://mirror.roytang.net/tags/automated-tests/index.xml" rel="self" type="application/rss+xml" />
      
          
      
        <item>
            <title>New note
</title>
            <link>https://mirror.roytang.net/2009/12/1951373/</link>
            <pubDate>Wed, 23 Dec 2009 08:20:52 +0000</pubDate>
            <author>hello@roytang.net (Roy Tang)</author>
            <guid>https://mirror.roytang.net/2009/12/1951373/</guid>
            <description>
            

            &lt;p&gt;We&amp;rsquo;re working on a project with a number of applets that has to work across a large range of OS (WIndows, Mac, Linux), browsers (IE, FF, Safari, etc) and Java versions (1.5+), and it often happens that a fix we apply will cause some sort of security exception an another platform or some other error.&lt;/p&gt;
&lt;p&gt;Is there any way for us to prepare automated tests to immediately catch those problems in different platforms? I think it&amp;rsquo;s not necessary to check that the gui parts are appearing as intended, but just to detect whether unexpected exceptions are occuring.&lt;/p&gt;



            </description>
        </item>
    
    </channel>
  </rss>